"""
Treinamento de √Årvore de Decis√£o (White Box Model)

Autor: Frederico Guilherme Santana da Silva Filho
Institui√ß√£o: Programa de Doutorado em Engenharia El√©trica - UFPA
Projeto: Framework Multi-Paradigma para Predi√ß√£o de Abandono de Tratamento de Tuberculose

Data de Cria√ß√£o: 2024-06-10
√öltima Modifica√ß√£o: 2025-11-20

Descri√ß√£o:
    Implementa√ß√£o de √Årvore de Decis√£o como modelo interpret√°vel (white box).
    
    Conforme mencionado na tese, modelos interpret√°veis s√£o essenciais para
    contextos de sa√∫de, permitindo que profissionais entendam as regras de decis√£o.
    
    Caracter√≠sticas:
    - Totalmente interpret√°vel (regras de decis√£o expl√≠citas)
    - Crit√©rio: Gini
    - Max depth: 10 (para manter interpretabilidade)
    - Min samples split: 20
    - Min samples leaf: 10
    - Class weight: balanced

Licen√ßa: MIT
"""

import numpy as np
import pandas as pd
from sklearn.tree import DecisionTreeClassifier, export_text
from sklearn.metrics import (
    f1_score, roc_auc_score, accuracy_score, precision_score,
    recall_score, matthews_corrcoef, confusion_matrix
)
import joblib
import logging
from pathlib import Path
from typing import Dict, Tuple, Any, Optional

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class DecisionTreeWhiteBox:
    """
    Modelo de √Årvore de Decis√£o Interpret√°vel (White Box).
    
    Implementa um modelo completamente interpret√°vel onde cada caminho
    na √°rvore representa uma regra de decis√£o expl√≠cita.
    """
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """
        Inicializa o treinador de √Årvore de Decis√£o.
        
        Par√¢metros:
        -----------
        config : Dict, optional
            Dicion√°rio de configura√ß√µes
        """
        self.config = config or {}
        
        # Hiperpar√¢metros
        self.hyperparams = {
            'criterion': 'gini',  # Crit√©rio de divis√£o
            'max_depth': 10,  # Profundidade m√°xima (para interpretabilidade)
            'min_samples_split': 20,
            'min_samples_leaf': 10,
            'class_weight': 'balanced',  # Balanceamento autom√°tico
            'random_state': 42
        }
        
        self.model = None
        self.is_fitted = False
        self.training_history = {}
        self.feature_names = None
        
        logger.info("‚úÖ DecisionTreeWhiteBox inicializado")
        logger.info(f"   Hiperpar√¢metros: {self.hyperparams}")
    
    def build_model(self) -> DecisionTreeClassifier:
        """
        Constr√≥i o modelo de √Årvore de Decis√£o.
        
        Retorna:
        --------
        DecisionTreeClassifier
            Modelo de √Årvore de Decis√£o configurado
        """
        self.model = DecisionTreeClassifier(**self.hyperparams)
        logger.info("‚úÖ Modelo de √Årvore de Decis√£o constru√≠do")
        return self.model
    
    def train(
        self,
        X_train: np.ndarray,
        y_train: np.ndarray,
        X_val: Optional[np.ndarray] = None,
        y_val: Optional[np.ndarray] = None,
        feature_names: Optional[list] = None
    ) -> Dict[str, float]:
        """
        Treina o modelo de √Årvore de Decis√£o.
        
        Par√¢metros:
        -----------
        X_train : np.ndarray
            Features de treino
        y_train : np.ndarray
            Target de treino
        X_val : np.ndarray, optional
            Features de valida√ß√£o
        y_val : np.ndarray, optional
            Target de valida√ß√£o
        feature_names : list, optional
            Nomes das features
            
        Retorna:
        --------
        Dict[str, float]
            M√©tricas de treino
        """
        logger.info("Iniciando treinamento da √Årvore de Decis√£o...")
        
        # Armazenar nomes das features
        self.feature_names = feature_names
        
        # Construir modelo se n√£o existir
        if self.model is None:
            self.build_model()
        
        # Treinar
        self.model.fit(X_train, y_train)
        self.is_fitted = True
        
        # Calcular m√©tricas de treino
        y_pred_train = self.model.predict(X_train)
        y_proba_train = self.model.predict_proba(X_train)[:, 1]
        
        train_metrics = {
            'f1_score': f1_score(y_train, y_pred_train),
            'auc': roc_auc_score(y_train, y_proba_train),
            'accuracy': accuracy_score(y_train, y_pred_train),
            'precision': precision_score(y_train, y_pred_train),
            'recall': recall_score(y_train, y_pred_train),
            'mcc': matthews_corrcoef(y_train, y_pred_train)
        }
        
        logger.info(f"‚úÖ Treinamento conclu√≠do")
        logger.info(f"   F1-Score (treino): {train_metrics['f1_score']:.4f}")
        logger.info(f"   AUC (treino): {train_metrics['auc']:.4f}")
        
        # Valida√ß√£o se dados forem fornecidos
        if X_val is not None and y_val is not None:
            y_pred_val = self.model.predict(X_val)
            y_proba_val = self.model.predict_proba(X_val)[:, 1]
            
            val_metrics = {
                'f1_score': f1_score(y_val, y_pred_val),
                'auc': roc_auc_score(y_val, y_proba_val),
                'accuracy': accuracy_score(y_val, y_pred_val),
                'precision': precision_score(y_val, y_pred_val),
                'recall': recall_score(y_val, y_pred_val),
                'mcc': matthews_corrcoef(y_val, y_pred_val)
            }
            
            logger.info(f"   F1-Score (valida√ß√£o): {val_metrics['f1_score']:.4f}")
            logger.info(f"   AUC (valida√ß√£o): {val_metrics['auc']:.4f}")
            
            self.training_history['validation'] = val_metrics
        
        self.training_history['training'] = train_metrics
        
        return train_metrics
    
    def predict(self, X: np.ndarray) -> np.ndarray:
        """
        Faz predi√ß√µes com o modelo treinado.
        
        Par√¢metros:
        -----------
        X : np.ndarray
            Features para predi√ß√£o
            
        Retorna:
        --------
        np.ndarray
            Classes preditas (0 ou 1)
        """
        if not self.is_fitted:
            raise ValueError("Modelo n√£o foi treinado. Chame train() primeiro.")
        
        return self.model.predict(X)
    
    def predict_proba(self, X: np.ndarray) -> np.ndarray:
        """
        Retorna probabilidades de predi√ß√£o.
        
        Par√¢metros:
        -----------
        X : np.ndarray
            Features para predi√ß√£o
            
        Retorna:
        --------
        np.ndarray
            Probabilidades para cada classe
        """
        if not self.is_fitted:
            raise ValueError("Modelo n√£o foi treinado. Chame train() primeiro.")
        
        return self.model.predict_proba(X)
    
    def get_feature_importance(self, feature_names: Optional[list] = None) -> pd.DataFrame:
        """
        Retorna import√¢ncia das features.
        
        Par√¢metros:
        -----------
        feature_names : list, optional
            Nomes das features
            
        Retorna:
        --------
        pd.DataFrame
            DataFrame com import√¢ncia das features
        """
        if not self.is_fitted:
            raise ValueError("Modelo n√£o foi treinado. Chame train() primeiro.")
        
        importances = self.model.feature_importances_
        
        if feature_names is None:
            feature_names = [f"Feature_{i}" for i in range(len(importances))]
        
        importance_df = pd.DataFrame({
            'feature': feature_names,
            'importance': importances
        }).sort_values('importance', ascending=False)
        
        return importance_df
    
    def get_tree_rules(self) -> str:
        """
        Retorna as regras da √°rvore em formato texto (interpretabilidade).
        
        Retorna:
        --------
        str
            Representa√ß√£o textual das regras da √°rvore
        """
        if not self.is_fitted:
            raise ValueError("Modelo n√£o foi treinado. Chame train() primeiro.")
        
        feature_names = self.feature_names or [f"Feature_{i}" for i in range(self.model.n_features_in_)]
        
        tree_rules = export_text(self.model, feature_names=feature_names)
        
        return tree_rules
    
    def evaluate(
        self,
        X_test: np.ndarray,
        y_test: np.ndarray
    ) -> Dict[str, float]:
        """
        Avalia o modelo em dados de teste.
        
        Par√¢metros:
        -----------
        X_test : np.ndarray
            Features de teste
        y_test : np.ndarray
            Target de teste
            
        Retorna:
        --------
        Dict[str, float]
            M√©tricas de teste
        """
        if not self.is_fitted:
            raise ValueError("Modelo n√£o foi treinado. Chame train() primeiro.")
        
        y_pred = self.predict(X_test)
        y_proba = self.predict_proba(X_test)[:, 1]
        
        metrics = {
            'f1_score': f1_score(y_test, y_pred),
            'auc': roc_auc_score(y_test, y_proba),
            'accuracy': accuracy_score(y_test, y_pred),
            'precision': precision_score(y_test, y_pred),
            'recall': recall_score(y_test, y_pred),
            'mcc': matthews_corrcoef(y_test, y_pred)
        }
        
        logger.info("üìä M√©tricas de Teste (√Årvore de Decis√£o - White Box):")
        logger.info(f"   F1-Score: {metrics['f1_score']:.4f}")
        logger.info(f"   AUC: {metrics['auc']:.4f}")
        logger.info(f"   Accuracy: {metrics['accuracy']:.4f}")
        logger.info(f"   Precision: {metrics['precision']:.4f}")
        logger.info(f"   Recall: {metrics['recall']:.4f}")
        logger.info(f"   MCC: {metrics['mcc']:.4f}")
        
        return metrics
    
    def save(self, filepath: str):
        """
        Salva o modelo treinado.
        
        Par√¢metros:
        -----------
        filepath : str
            Caminho para salvar o modelo
        """
        if not self.is_fitted:
            raise ValueError("Modelo n√£o foi treinado. Chame train() primeiro.")
        
        Path(filepath).parent.mkdir(parents=True, exist_ok=True)
        
        model_data = {
            'model': self.model,
            'feature_names': self.feature_names
        }
        
        joblib.dump(model_data, filepath)
        logger.info(f"‚úÖ Modelo salvo em: {filepath}")
    
    def load(self, filepath: str):
        """
        Carrega um modelo treinado.
        
        Par√¢metros:
        -----------
        filepath : str
            Caminho do modelo salvo
        """
        model_data = joblib.load(filepath)
        
        self.model = model_data['model']
        self.feature_names = model_data['feature_names']
        self.is_fitted = True
        
        logger.info(f"‚úÖ Modelo carregado de: {filepath}")


def main():
    """Exemplo de uso da √Årvore de Decis√£o."""
    
    # Dados de exemplo
    np.random.seed(42)
    n_samples = 1000
    n_features = 78
    
    X = np.random.randn(n_samples, n_features)
    y = np.random.randint(0, 2, n_samples)
    
    # Dividir em treino e teste
    split_idx = int(0.8 * n_samples)
    X_train, X_test = X[:split_idx], X[split_idx:]
    y_train, y_test = y[:split_idx], y[split_idx:]
    
    # Criar e treinar
    trainer = DecisionTreeWhiteBox()
    trainer.train(X_train, y_train, X_test, y_test)
    
    # Avaliar
    metrics = trainer.evaluate(X_test, y_test)
    
    # Feature importance
    importance_df = trainer.get_feature_importance()
    print("\nüìä Top 10 Features mais Importantes:")
    print(importance_df.head(10))
    
    # Regras da √°rvore
    print("\nüìã Regras da √Årvore (primeiras 50 linhas):")
    tree_rules = trainer.get_tree_rules()
    print("\\n".join(tree_rules.split("\\n")[:50]))
    
    # Salvar
    trainer.save('results/ml_models/decision_tree_white_box.pkl')


if __name__ == "__main__":
    main()
