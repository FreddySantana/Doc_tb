"""
M√≥dulo de Quantifica√ß√£o de Incerteza para o Ensemble

Autor: Frederico Guilherme Santana da Silva Filho
Institui√ß√£o: Programa de Doutorado em Engenharia El√©trica - UFPA
Projeto: Framework Multi-Paradigma para Predi√ß√£o de Abandono de Tratamento de Tuberculose

Data de Cria√ß√£o: 2024-08-15
√öltima Modifica√ß√£o: 2025-11-20

Descri√ß√£o:
    Este m√≥dulo implementa a quantifica√ß√£o de incerteza conforme as Equa√ß√µes 82-84 da tese.
    
    Equa√ß√£o 82 (Monte Carlo Dropout):
    √õ_MC(x) = ‚àö(1/T Œ£(≈∑_t(x) - ≈∑_MC(x))¬≤)
    
    Equa√ß√£o 83 (Vari√¢ncia do Ensemble):
    U_ens(x) = ‚àö(1/4 Œ£(≈∑_i(x) - ≈∑_ensemble(x))¬≤)
    
    Equa√ß√£o 84 (Incerteza Total):
    U(x) = 0.6 ¬∑ U_MC(x) + 0.4 ¬∑ U_ens(x)

Licen√ßa: MIT
"""

import numpy as np
from typing import Tuple, Optional
import logging

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class UncertaintyQuantification:
    """
    Classe para quantifica√ß√£o de incerteza no ensemble.
    
    Combina duas fontes de incerteza:
    1. Incerteza epist√™mica (Monte Carlo Dropout) - U_MC
    2. Vari√¢ncia do ensemble (entre os 4 paradigmas) - U_ens
    
    A incerteza total √© uma combina√ß√£o ponderada dessas duas fontes.
    """
    
    def __init__(self, mc_weight: float = 0.6, ens_weight: float = 0.4):
        """
        Inicializa o m√≥dulo de quantifica√ß√£o de incerteza.
        
        Par√¢metros:
        -----------
        mc_weight : float
            Peso da incerteza Monte Carlo (padr√£o: 0.6)
        ens_weight : float
            Peso da vari√¢ncia do ensemble (padr√£o: 0.4)
        """
        assert abs(mc_weight + ens_weight - 1.0) < 1e-6, \
            f"Pesos devem somar 1.0, mas somam {mc_weight + ens_weight}"
        
        self.mc_weight = mc_weight
        self.ens_weight = ens_weight
        
        logger.info(f"‚úÖ Quantifica√ß√£o de Incerteza inicializada")
        logger.info(f"   - Peso Monte Carlo: {mc_weight}")
        logger.info(f"   - Peso Ensemble: {ens_weight}")
    
    def calculate_mc_dropout_uncertainty(
        self,
        mc_samples: np.ndarray
    ) -> np.ndarray:
        """
        Calcula a incerteza epist√™mica usando Monte Carlo Dropout.
        
        Conforme Equa√ß√£o 82 da tese:
        √õ_MC(x) = ‚àö(1/T Œ£(≈∑_t(x) - ≈∑_MC(x))¬≤)
        
        Par√¢metros:
        -----------
        mc_samples : np.ndarray
            Amostras de Monte Carlo Dropout
            Shape: (n_samples, T) onde T √© o n√∫mero de amostras
            
        Retorna:
        --------
        np.ndarray
            Incerteza Monte Carlo para cada amostra
            Shape: (n_samples,)
        """
        # Validar entrada
        assert mc_samples.ndim == 2, \
            f"mc_samples deve ter 2 dimens√µes, mas tem {mc_samples.ndim}"
        
        n_samples, T = mc_samples.shape
        
        # Calcular m√©dia das amostras (≈∑_MC)
        y_mc_mean = np.mean(mc_samples, axis=1)  # Shape: (n_samples,)
        
        # Calcular vari√¢ncia: 1/T Œ£(≈∑_t - ≈∑_MC)¬≤
        variance = np.mean(
            (mc_samples - y_mc_mean[:, np.newaxis]) ** 2,
            axis=1
        )
        
        # Calcular desvio padr√£o (incerteza)
        u_mc = np.sqrt(variance)
        
        return u_mc
    
    def calculate_ensemble_variance(
        self,
        ml_proba: np.ndarray,
        drl_proba: np.ndarray,
        nlp_proba: np.ndarray,
        ensemble_proba: np.ndarray
    ) -> np.ndarray:
        """
        Calcula a vari√¢ncia entre as predi√ß√µes dos paradigmas.
        
        Conforme Equa√ß√£o 83 da tese:
        U_ens(x) = ‚àö(1/4 Œ£(≈∑_i(x) - ≈∑_ensemble(x))¬≤)
        
        Par√¢metros:
        -----------
        ml_proba : np.ndarray
            Probabilidades do ML (shape: n_samples)
        drl_proba : np.ndarray
            Probabilidades do DRL (shape: n_samples)
        nlp_proba : np.ndarray
            Probabilidades do NLP (shape: n_samples)
        ensemble_proba : np.ndarray
            Probabilidades do ensemble (shape: n_samples)
            
        Retorna:
        --------
        np.ndarray
            Vari√¢ncia do ensemble para cada amostra (shape: n_samples)
        """
        # Validar dimens√µes
        n_samples = len(ml_proba)
        assert len(drl_proba) == n_samples, "drl_proba deve ter mesmo tamanho que ml_proba"
        assert len(nlp_proba) == n_samples, "nlp_proba deve ter mesmo tamanho que ml_proba"
        assert len(ensemble_proba) == n_samples, "ensemble_proba deve ter mesmo tamanho que ml_proba"
        
        # Stack das predi√ß√µes: (n_samples, 3)
        paradigm_probas = np.column_stack([ml_proba, drl_proba, nlp_proba])
        
        # Calcular vari√¢ncia: 1/3 Œ£(≈∑_i - ≈∑_ensemble)¬≤
        # Nota: Usamos 3 paradigmas (ML, DRL, NLP), n√£o 4 (XAI foi removido)
        variance = np.mean(
            (paradigm_probas - ensemble_proba[:, np.newaxis]) ** 2,
            axis=1
        )
        
        # Calcular desvio padr√£o (vari√¢ncia do ensemble)
        u_ens = np.sqrt(variance)
        
        return u_ens
    
    def calculate_total_uncertainty(
        self,
        ml_proba: np.ndarray,
        drl_proba: np.ndarray,
        nlp_proba: np.ndarray,
        ensemble_proba: np.ndarray,
        mc_samples: Optional[np.ndarray] = None
    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """
        Calcula a incerteza total combinando Monte Carlo Dropout e vari√¢ncia do ensemble.
        
        Conforme Equa√ß√£o 84 da tese:
        U(x) = 0.6 ¬∑ U_MC(x) + 0.4 ¬∑ U_ens(x)
        
        Par√¢metros:
        -----------
        ml_proba : np.ndarray
            Probabilidades do ML
        drl_proba : np.ndarray
            Probabilidades do DRL
        nlp_proba : np.ndarray
            Probabilidades do NLP
        ensemble_proba : np.ndarray
            Probabilidades do ensemble
        mc_samples : np.ndarray, optional
            Amostras de Monte Carlo Dropout
            Se None, usa apenas a vari√¢ncia do ensemble
            
        Retorna:
        --------
        Tuple[np.ndarray, np.ndarray, np.ndarray]
            (u_total, u_mc, u_ens)
            - u_total: Incerteza total
            - u_mc: Incerteza Monte Carlo
            - u_ens: Vari√¢ncia do ensemble
        """
        # Calcular vari√¢ncia do ensemble
        u_ens = self.calculate_ensemble_variance(
            ml_proba, drl_proba, nlp_proba, ensemble_proba
        )
        
        # Calcular incerteza Monte Carlo se amostras forem fornecidas
        if mc_samples is not None:
            u_mc = self.calculate_mc_dropout_uncertainty(mc_samples)
        else:
            # Se n√£o h√° amostras MC, usar apenas vari√¢ncia do ensemble
            logger.warning("Amostras de Monte Carlo Dropout n√£o fornecidas. "
                          "Usando apenas vari√¢ncia do ensemble.")
            u_mc = np.zeros_like(u_ens)
        
        # Calcular incerteza total (Equa√ß√£o 84)
        u_total = self.mc_weight * u_mc + self.ens_weight * u_ens
        
        return u_total, u_mc, u_ens
    
    def get_uncertainty_metrics(
        self,
        u_total: np.ndarray,
        u_mc: np.ndarray,
        u_ens: np.ndarray
    ) -> dict:
        """
        Calcula m√©tricas de resumo para a incerteza.
        
        Par√¢metros:
        -----------
        u_total : np.ndarray
            Incerteza total
        u_mc : np.ndarray
            Incerteza Monte Carlo
        u_ens : np.ndarray
            Vari√¢ncia do ensemble
            
        Retorna:
        --------
        dict
            Dicion√°rio com m√©tricas de incerteza
        """
        metrics = {
            'u_total_mean': np.mean(u_total),
            'u_total_std': np.std(u_total),
            'u_total_min': np.min(u_total),
            'u_total_max': np.max(u_total),
            'u_mc_mean': np.mean(u_mc),
            'u_mc_std': np.std(u_mc),
            'u_ens_mean': np.mean(u_ens),
            'u_ens_std': np.std(u_ens),
            'mc_contribution': self.mc_weight,
            'ens_contribution': self.ens_weight
        }
        
        return metrics
    
    def print_uncertainty_report(self, metrics: dict):
        """
        Imprime um relat√≥rio de incerteza.
        
        Par√¢metros:
        -----------
        metrics : dict
            Dicion√°rio com m√©tricas de incerteza
        """
        print("\n" + "="*70)
        print("RELAT√ìRIO DE QUANTIFICA√á√ÉO DE INCERTEZA")
        print("="*70)
        
        print("\nüìä Incerteza Total U(x):")
        print(f"   M√©dia:  {metrics['u_total_mean']:.6f}")
        print(f"   Desvio: {metrics['u_total_std']:.6f}")
        print(f"   Min:    {metrics['u_total_min']:.6f}")
        print(f"   Max:    {metrics['u_total_max']:.6f}")
        
        print("\nüî¥ Incerteza Monte Carlo U_MC(x):")
        print(f"   M√©dia:  {metrics['u_mc_mean']:.6f}")
        print(f"   Desvio: {metrics['u_mc_std']:.6f}")
        print(f"   Contribui√ß√£o: {metrics['mc_contribution']*100:.1f}%")
        
        print("\nüü¢ Vari√¢ncia do Ensemble U_ens(x):")
        print(f"   M√©dia:  {metrics['u_ens_mean']:.6f}")
        print(f"   Desvio: {metrics['u_ens_std']:.6f}")
        print(f"   Contribui√ß√£o: {metrics['ens_contribution']*100:.1f}%")
        
        print("\n" + "="*70)


def example_usage():
    """Exemplo de uso do m√≥dulo de quantifica√ß√£o de incerteza."""
    
    # Criar inst√¢ncia
    uq = UncertaintyQuantification(mc_weight=0.6, ens_weight=0.4)
    
    # Dados de exemplo
    np.random.seed(42)
    n_samples = 100
    T = 50  # N√∫mero de amostras Monte Carlo
    
    # Simular probabilidades dos paradigmas
    ml_proba = np.random.rand(n_samples)
    drl_proba = np.random.rand(n_samples)
    nlp_proba = np.random.rand(n_samples)
    ensemble_proba = (0.50 * ml_proba + 0.30 * drl_proba + 0.20 * nlp_proba)
    
    # Simular amostras de Monte Carlo Dropout
    mc_samples = np.random.rand(n_samples, T)
    
    # Calcular incerteza total
    u_total, u_mc, u_ens = uq.calculate_total_uncertainty(
        ml_proba, drl_proba, nlp_proba, ensemble_proba, mc_samples
    )
    
    # Obter m√©tricas
    metrics = uq.get_uncertainty_metrics(u_total, u_mc, u_ens)
    
    # Imprimir relat√≥rio
    uq.print_uncertainty_report(metrics)
    
    print("\n‚úÖ Exemplo de uso conclu√≠do com sucesso!")


if __name__ == "__main__":
    example_usage()
