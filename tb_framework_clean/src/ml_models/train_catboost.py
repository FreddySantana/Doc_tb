"""
M√≥dulo para treinamento de modelo CatBoost

Autor: Frederico
Institui√ß√£o: Programa de Doutorado
Projeto: Framework Multi-Paradigma para Predi√ß√£o de Abandono de Tratamento de Tuberculose

Data de Cria√ß√£o: 2025-04-15
√öltima Modifica√ß√£o: 2025-07-20

Descri√ß√£o:
    Este m√≥dulo faz parte do framework multi-paradigma desenvolvido para predi√ß√£o
    de abandono de tratamento em pacientes com tuberculose. O framework integra
    t√©cnicas de Machine Learning, Deep Reinforcement Learning, Natural Language
    Processing e Explainable AI.

Licen√ßa: MIT
"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Treinamento de Modelo CatBoost

Implementa treinamento de CatBoost conforme descrito na Se√ß√£o 4.3 da tese.
CatBoost √© otimizado para vari√°veis categ√≥ricas e reduz overfitting.

Refer√™ncia: Prokhorenkova, L., et al. (2018). CatBoost: unbiased boosting with categorical features.
"""

import pandas as pd
import numpy as np
from pathlib import Path
from typing import Dict, Any, Optional
import logging
import json

import catboost as cb
from sklearn.model_selection import cross_val_score, StratifiedKFold
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    roc_auc_score, confusion_matrix, classification_report
)

from src.utils import setup_logger, save_model, load_config

logger = setup_logger(__name__)


class CatBoostTrainer:
    """
    Treinador de modelo CatBoost.
    
    CatBoost usa ordered boosting e trata vari√°veis categ√≥ricas
    nativamente sem necessidade de encoding pr√©vio.
    
    Principais caracter√≠sticas:
    - Ordered boosting: reduz overfitting
    - Target statistics: encoding de categ√≥ricas
    - Oblivious trees: √°rvores sim√©tricas
    
    Attributes:
        config: Dicion√°rio de configura√ß√µes
        model: Modelo CatBoost treinado
        feature_importance: Import√¢ncia das features
    """
    
    def __init__(self, config: Dict[str, Any] = None, random_state: int = None):
        """
        Inicializa o treinador.
        
        Args:
            config: Dicion√°rio de configura√ß√µes (opcional)
            random_state: Seed para reprodutibilidade (opcional)
        """
        # Aceitar tanto dict quanto int para compatibilidade
        if isinstance(config, int):
            random_state = config
            config = {}
        elif config is None:
            config = {}
        
        self.config = config
        self.random_state = random_state if random_state is not None else config.get('random_state', 42)
        
        # Hiperpar√¢metros padr√£o otimizados
        self.params = {
            'depth': 6,
            'learning_rate': 0.1,
            'iterations': 100,
            'loss_function': 'Logloss',
            'eval_metric': 'Logloss',
            'random_state': self.random_state,
            'verbose': False,
            'auto_class_weights': 'Balanced',  # Para dados desbalanceados
            'subsample': 0.8,
            'l2_leaf_reg': 3.0,  # Regulariza√ß√£o L2
            'bootstrap_type': 'Bernoulli',
            'sampling_frequency': 'PerTree'
        }
        
        self.model = None
        self.feature_importance = None
        self.training_history = {}
        
        self.output_dir = Path('results/ml_models/catboost')
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        logger.info('CatBoostTrainer inicializado')
    
    def train(
        self,
        X_train: pd.DataFrame,
        y_train: pd.Series,
        X_val: Optional[pd.DataFrame] = None,
        y_val: Optional[pd.Series] = None,
        use_cross_validation: bool = False,
        cv_folds: int = 5
    ) -> cb.CatBoostClassifier:
        """
        Treina o modelo CatBoost.
        
        Args:
            X_train: Features de treino
            y_train: Target de treino
            X_val: Features de valida√ß√£o (opcional)
            y_val: Target de valida√ß√£o (opcional)
            use_cross_validation: Se deve usar valida√ß√£o cruzada
            cv_folds: N√∫mero de folds para CV
        
        Returns:
            Modelo treinado
        """
        logger.info('='*80)
        logger.info('TREINANDO MODELO CATBOOST')
        logger.info('='*80)
        
        logger.info(f'Dimens√µes do conjunto de treino: {X_train.shape}')
        logger.info(f'Distribui√ß√£o da classe alvo:')
        logger.info(f'  Classe 0: {(y_train == 0).sum()} ({(y_train == 0).sum() / len(y_train) * 100:.2f}%)')
        logger.info(f'  Classe 1: {(y_train == 1).sum()} ({(y_train == 1).sum() / len(y_train) * 100:.2f}%)')
        
        # Criar modelo
        self.model = cb.CatBoostClassifier(**self.params)
        
        # Valida√ß√£o cruzada (opcional)
        if use_cross_validation:
            logger.info(f'Executando valida√ß√£o cruzada com {cv_folds} folds...')
            cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=self.random_state)
            cv_scores = cross_val_score(
                self.model, X_train, y_train,
                cv=cv, scoring='f1', n_jobs=-1
            )
            logger.info(f'F1-Score CV: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})')
            self.training_history['cv_scores'] = cv_scores.tolist()
        
        # Treinar modelo
        if X_val is not None and y_val is not None:
            logger.info('Treinando com conjunto de valida√ß√£o...')
            eval_set = cb.Pool(X_val, y_val)
            self.model.fit(
                X_train, y_train,
                eval_set=eval_set,
                use_best_model=True,
                plot=False
            )
            
            # Salvar hist√≥rico de treinamento
            if hasattr(self.model, 'evals_result_'):
                self.training_history['val_loss'] = self.model.evals_result_['validation']['Logloss']
        else:
            logger.info('Treinando sem conjunto de valida√ß√£o...')
            self.model.fit(X_train, y_train)
        
        # Extrair import√¢ncia das features
        self.feature_importance = pd.DataFrame({
            'feature': X_train.columns,
            'importance': self.model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        logger.info('Modelo treinado com sucesso!')
        logger.info(f'N√∫mero de itera√ß√µes: {self.model.tree_count_}')
        
        # Salvar top 10 features mais importantes
        logger.info('\nTop 10 features mais importantes:')
        for idx, row in self.feature_importance.head(10).iterrows():
            logger.info(f'  {row["feature"]}: {row["importance"]:.4f}')
        
        return self.model
    
    def evaluate(
        self,
        X_test: pd.DataFrame,
        y_test: pd.Series,
        threshold: float = 0.5
    ) -> Dict[str, float]:
        """
        Avalia o modelo.
        
        Args:
            X_test: Features de teste
            y_test: Target de teste
            threshold: Limiar de decis√£o
        
        Returns:
            Dicion√°rio com m√©tricas
        """
        logger.info('='*80)
        logger.info('AVALIANDO MODELO CATBOOST')
        logger.info('='*80)
        
        # Predi√ß√µes
        y_prob = self.model.predict_proba(X_test)[:, 1]
        y_pred = (y_prob >= threshold).astype(int)
        
        # Calcular m√©tricas
        metrics = {
            'accuracy': accuracy_score(y_test, y_pred),
            'precision': precision_score(y_test, y_pred, zero_division=0),
            'recall': recall_score(y_test, y_pred, zero_division=0),
            'f1_score': f1_score(y_test, y_pred, zero_division=0),
            'auc': roc_auc_score(y_test, y_prob)
        }
        
        # Matriz de confus√£o
        cm = confusion_matrix(y_test, y_pred)
        tn, fp, fn, tp = cm.ravel()
        
        metrics['true_negatives'] = int(tn)
        metrics['false_positives'] = int(fp)
        metrics['false_negatives'] = int(fn)
        metrics['true_positives'] = int(tp)
        metrics['specificity'] = tn / (tn + fp) if (tn + fp) > 0 else 0
        
        logger.info('M√©tricas de Desempenho:')
        logger.info(f'  Acur√°cia: {metrics["accuracy"]:.4f}')
        logger.info(f'  Precis√£o: {metrics["precision"]:.4f}')
        logger.info(f'  Recall (Sensibilidade): {metrics["recall"]:.4f}')
        logger.info(f'  F1-Score: {metrics["f1_score"]:.4f}')
        logger.info(f'  ROC-AUC: {metrics["auc"]:.4f}')
        logger.info(f'  Especificidade: {metrics["specificity"]:.4f}')
        
        logger.info('\nMatriz de Confus√£o:')
        logger.info(f'  TN: {tn}  FP: {fp}')
        logger.info(f'  FN: {fn}  TP: {tp}')
        
        # Relat√≥rio de classifica√ß√£o
        logger.info('\nRelat√≥rio de Classifica√ß√£o:')
        logger.info('\n' + classification_report(y_test, y_pred, target_names=['N√£o-Abandono', 'Abandono']))
        
        return metrics
    
    def get_feature_importance(self, top_n: int = 20) -> pd.DataFrame:
        """
        Retorna as features mais importantes.
        
        Args:
            top_n: N√∫mero de features a retornar
        
        Returns:
            DataFrame com features e import√¢ncias
        """
        if self.feature_importance is None:
            raise ValueError('Modelo n√£o foi treinado ainda')
        
        return self.feature_importance.head(top_n)
    
    def save(self, filename: str = 'catboost_model.pkl') -> None:
        """
        Salva o modelo treinado.
        
        Args:
            filename: Nome do arquivo
        """
        if self.model is None:
            raise ValueError('Modelo n√£o foi treinado ainda')
        
        # Salvar modelo
        model_path = self.output_dir / filename
        save_model(self.model, model_path)
        logger.info(f'Modelo salvo em {model_path}')
        
        # Salvar import√¢ncia das features
        if self.feature_importance is not None:
            importance_path = self.output_dir / 'feature_importance.csv'
            self.feature_importance.to_csv(importance_path, index=False)
            logger.info(f'Import√¢ncia das features salva em {importance_path}')
        
        # Salvar hist√≥rico de treinamento
        if self.training_history:
            history_path = self.output_dir / 'training_history.json'
            with open(history_path, 'w') as f:
                json.dump(self.training_history, f, indent=2)
            logger.info(f'Hist√≥rico de treinamento salvo em {history_path}')
        
        # Salvar hiperpar√¢metros
        params_path = self.output_dir / 'hyperparameters.json'
        # Converter par√¢metros para formato serializ√°vel
        serializable_params = {k: str(v) if not isinstance(v, (int, float, bool, str, type(None))) else v 
                              for k, v in self.params.items()}
        with open(params_path, 'w') as f:
            json.dump(serializable_params, f, indent=2)
        logger.info(f'Hiperpar√¢metros salvos em {params_path}')


def main():
    """Fun√ß√£o principal para execu√ß√£o standalone"""
    from src.utils import load_data
    
    logger.info('Iniciando treinamento de CatBoost')
    
    # Carregar configura√ß√£o
    config = load_config()
    trainer = CatBoostTrainer(config)
    
    # Carregar dados
    logger.info('Carregando dados...')
    train_df = load_data('data/processed/train_balanced.csv')
    test_df = load_data('data/processed/test.csv')
    
    target_col = config['target']['column_name']
    X_train = train_df.drop(target_col, axis=1)
    y_train = train_df[target_col]
    X_test = test_df.drop(target_col, axis=1)
    y_test = test_df[target_col]
    
    # Treinar
    trainer.train(X_train, y_train, use_cross_validation=True)
    
    # Avaliar
    metrics = trainer.evaluate(X_test, y_test)
    
    # Salvar
    trainer.save()
    
    # Exibir top features
    print('\n' + '='*80)
    print('TOP 20 FEATURES MAIS IMPORTANTES')
    print('='*80)
    print(trainer.get_feature_importance(top_n=20).to_string(index=False))
    
    print('\n' + '='*80)
    print('‚úÖ TREINAMENTO DE CATBOOST CONCLU√çDO COM SUCESSO!')
    print('='*80)
    print(f'\nüìä M√©tricas Finais:')
    print(f'   Acur√°cia: {metrics["accuracy"]:.4f}')
    print(f'   Precis√£o: {metrics["precision"]:.4f}')
    print(f'   Recall: {metrics["recall"]:.4f}')
    print(f'   F1-Score: {metrics["f1_score"]:.4f}')
    print(f'   ROC-AUC: {metrics["auc"]:.4f}')
    print(f'\nüìÅ Resultados salvos em: {trainer.output_dir}')
    print('='*80)


if __name__ == '__main__':
    main()
