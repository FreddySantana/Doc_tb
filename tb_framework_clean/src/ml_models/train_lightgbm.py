"""
M√≥dulo para treinamento de modelo LightGBM

Autor: Frederico
Institui√ß√£o: Programa de Doutorado
Projeto: Framework Multi-Paradigma para Predi√ß√£o de Abandono de Tratamento de Tuberculose

Data de Cria√ß√£o: 2025-04-12
√öltima Modifica√ß√£o: 2025-07-18

Descri√ß√£o:
    Este m√≥dulo faz parte do framework multi-paradigma desenvolvido para predi√ß√£o
    de abandono de tratamento em pacientes com tuberculose. O framework integra
    t√©cnicas de Machine Learning, Deep Reinforcement Learning, Natural Language
    Processing e Explainable AI.

Licen√ßa: MIT
"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Treinamento de Modelo LightGBM

Implementa treinamento de LightGBM conforme descrito na Se√ß√£o 4.3 da tese.
LightGBM √© otimizado para velocidade e efici√™ncia em grandes datasets.

Refer√™ncia: Ke, G., et al. (2017). LightGBM: A highly efficient gradient boosting decision tree.
"""

import pandas as pd
import numpy as np
from pathlib import Path
from typing import Dict, Any, Optional
import logging
import json

import lightgbm as lgb
from sklearn.model_selection import cross_val_score, StratifiedKFold
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    roc_auc_score, confusion_matrix, classification_report
)

from src.utils import setup_logger, save_model, load_config

logger = setup_logger(__name__)


class LightGBMTrainer:
    """
    Treinador de modelo LightGBM.
    
    LightGBM usa gradient-based one-side sampling (GOSS) e
    exclusive feature bundling (EFB) para efici√™ncia.
    
    Principais caracter√≠sticas:
    - Crescimento de √°rvore leaf-wise (mais profundo)
    - GOSS: mant√©m inst√¢ncias com gradientes grandes
    - EFB: agrupa features mutuamente exclusivas
    
    Attributes:
        config: Dicion√°rio de configura√ß√µes
        model: Modelo LightGBM treinado
        feature_importance: Import√¢ncia das features
    """
    
    def __init__(self, config: Dict[str, Any] = None, random_state: int = None):
        """
        Inicializa o treinador.
        
        Args:
            config: Dicion√°rio de configura√ß√µes (opcional)
            random_state: Seed para reprodutibilidade (opcional)
        """
        # Aceitar tanto dict quanto int para compatibilidade
        if isinstance(config, int):
            random_state = config
            config = {}
        elif config is None:
            config = {}
        
        self.config = config
        self.random_state = random_state if random_state is not None else config.get('random_state', 42)
        
        # Hiperpar√¢metros padr√£o otimizados
        self.params = {
            'max_depth': 6,
            'learning_rate': 0.1,
            'n_estimators': 100,
            'objective': 'binary',
            'metric': 'binary_logloss',
            'random_state': self.random_state,
            'n_jobs': -1,
            'verbose': -1,
            'is_unbalance': True,  # Para dados desbalanceados
            'subsample': 0.8,
            'colsample_bytree': 0.8,
            'reg_alpha': 0.1,
            'reg_lambda': 1.0,
            'min_child_samples': 20
        }
        
        self.model = None
        self.feature_importance = None
        self.training_history = {}
        
        self.output_dir = Path('results/ml_models/lightgbm')
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        logger.info('LightGBMTrainer inicializado')
    
    def train(
        self,
        X_train: pd.DataFrame,
        y_train: pd.Series,
        X_val: Optional[pd.DataFrame] = None,
        y_val: Optional[pd.Series] = None,
        use_cross_validation: bool = False,
        cv_folds: int = 5
    ) -> lgb.LGBMClassifier:
        """
        Treina o modelo LightGBM.
        
        Args:
            X_train: Features de treino
            y_train: Target de treino
            X_val: Features de valida√ß√£o (opcional)
            y_val: Target de valida√ß√£o (opcional)
            use_cross_validation: Se deve usar valida√ß√£o cruzada
            cv_folds: N√∫mero de folds para CV
        
        Returns:
            Modelo treinado
        """
        logger.info('='*80)
        logger.info('TREINANDO MODELO LIGHTGBM')
        logger.info('='*80)
        
        logger.info(f'Dimens√µes do conjunto de treino: {X_train.shape}')
        logger.info(f'Distribui√ß√£o da classe alvo:')
        logger.info(f'  Classe 0: {(y_train == 0).sum()} ({(y_train == 0).sum() / len(y_train) * 100:.2f}%)')
        logger.info(f'  Classe 1: {(y_train == 1).sum()} ({(y_train == 1).sum() / len(y_train) * 100:.2f}%)')
        
        # Criar modelo
        self.model = lgb.LGBMClassifier(**self.params)
        
        # Valida√ß√£o cruzada (opcional)
        if use_cross_validation:
            logger.info(f'Executando valida√ß√£o cruzada com {cv_folds} folds...')
            cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=self.random_state)
            cv_scores = cross_val_score(
                self.model, X_train, y_train,
                cv=cv, scoring='f1', n_jobs=-1
            )
            logger.info(f'F1-Score CV: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})')
            self.training_history['cv_scores'] = cv_scores.tolist()
        
        # Treinar modelo
        if X_val is not None and y_val is not None:
            logger.info('Treinando com conjunto de valida√ß√£o...')
            self.model.fit(
                X_train, y_train,
                eval_set=[(X_val, y_val)],
                eval_metric='binary_logloss'
            )
            
            # Salvar hist√≥rico de treinamento
            if hasattr(self.model, 'evals_result_'):
                self.training_history['val_loss'] = self.model.evals_result_['valid_0']['binary_logloss']
        else:
            logger.info('Treinando sem conjunto de valida√ß√£o...')
            self.model.fit(X_train, y_train)
        
        # Extrair import√¢ncia das features
        self.feature_importance = pd.DataFrame({
            'feature': X_train.columns,
            'importance': self.model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        logger.info('Modelo treinado com sucesso!')
        logger.info(f'N√∫mero de √°rvores: {self.model.n_estimators}')
        
        # Salvar top 10 features mais importantes
        logger.info('\nTop 10 features mais importantes:')
        for idx, row in self.feature_importance.head(10).iterrows():
            logger.info(f'  {row["feature"]}: {row["importance"]:.4f}')
        
        return self.model
    
    def evaluate(
        self,
        X_test: pd.DataFrame,
        y_test: pd.Series,
        threshold: float = 0.5
    ) -> Dict[str, float]:
        """
        Avalia o modelo.
        
        Args:
            X_test: Features de teste
            y_test: Target de teste
            threshold: Limiar de decis√£o
        
        Returns:
            Dicion√°rio com m√©tricas
        """
        logger.info('='*80)
        logger.info('AVALIANDO MODELO LIGHTGBM')
        logger.info('='*80)
        
        # Predi√ß√µes
        y_prob = self.model.predict_proba(X_test)[:, 1]
        y_pred = (y_prob >= threshold).astype(int)
        
        # Calcular m√©tricas
        metrics = {
            'accuracy': accuracy_score(y_test, y_pred),
            'precision': precision_score(y_test, y_pred, zero_division=0),
            'recall': recall_score(y_test, y_pred, zero_division=0),
            'f1_score': f1_score(y_test, y_pred, zero_division=0),
            'auc': roc_auc_score(y_test, y_prob)
        }
        
        # Matriz de confus√£o
        cm = confusion_matrix(y_test, y_pred)
        tn, fp, fn, tp = cm.ravel()
        
        metrics['true_negatives'] = int(tn)
        metrics['false_positives'] = int(fp)
        metrics['false_negatives'] = int(fn)
        metrics['true_positives'] = int(tp)
        metrics['specificity'] = tn / (tn + fp) if (tn + fp) > 0 else 0
        
        logger.info('M√©tricas de Desempenho:')
        logger.info(f'  Acur√°cia: {metrics["accuracy"]:.4f}')
        logger.info(f'  Precis√£o: {metrics["precision"]:.4f}')
        logger.info(f'  Recall (Sensibilidade): {metrics["recall"]:.4f}')
        logger.info(f'  F1-Score: {metrics["f1_score"]:.4f}')
        logger.info(f'  ROC-AUC: {metrics["auc"]:.4f}')
        logger.info(f'  Especificidade: {metrics["specificity"]:.4f}')
        
        logger.info('\nMatriz de Confus√£o:')
        logger.info(f'  TN: {tn}  FP: {fp}')
        logger.info(f'  FN: {fn}  TP: {tp}')
        
        # Relat√≥rio de classifica√ß√£o
        logger.info('\nRelat√≥rio de Classifica√ß√£o:')
        logger.info('\n' + classification_report(y_test, y_pred, target_names=['N√£o-Abandono', 'Abandono']))
        
        return metrics
    
    def get_feature_importance(self, top_n: int = 20) -> pd.DataFrame:
        """
        Retorna as features mais importantes.
        
        Args:
            top_n: N√∫mero de features a retornar
        
        Returns:
            DataFrame com features e import√¢ncias
        """
        if self.feature_importance is None:
            raise ValueError('Modelo n√£o foi treinado ainda')
        
        return self.feature_importance.head(top_n)
    
    def save(self, filename: str = 'lightgbm_model.pkl') -> None:
        """
        Salva o modelo treinado.
        
        Args:
            filename: Nome do arquivo
        """
        if self.model is None:
            raise ValueError('Modelo n√£o foi treinado ainda')
        
        # Salvar modelo
        model_path = self.output_dir / filename
        save_model(self.model, model_path)
        logger.info(f'Modelo salvo em {model_path}')
        
        # Salvar import√¢ncia das features
        if self.feature_importance is not None:
            importance_path = self.output_dir / 'feature_importance.csv'
            self.feature_importance.to_csv(importance_path, index=False)
            logger.info(f'Import√¢ncia das features salva em {importance_path}')
        
        # Salvar hist√≥rico de treinamento
        if self.training_history:
            history_path = self.output_dir / 'training_history.json'
            with open(history_path, 'w') as f:
                json.dump(self.training_history, f, indent=2)
            logger.info(f'Hist√≥rico de treinamento salvo em {history_path}')
        
        # Salvar hiperpar√¢metros
        params_path = self.output_dir / 'hyperparameters.json'
        with open(params_path, 'w') as f:
            json.dump(self.params, f, indent=2)
        logger.info(f'Hiperpar√¢metros salvos em {params_path}')


def main():
    """Fun√ß√£o principal para execu√ß√£o standalone"""
    from src.utils import load_data
    
    logger.info('Iniciando treinamento de LightGBM')
    
    # Carregar configura√ß√£o
    config = load_config()
    trainer = LightGBMTrainer(config)
    
    # Carregar dados
    logger.info('Carregando dados...')
    train_df = load_data('data/processed/train_balanced.csv')
    test_df = load_data('data/processed/test.csv')
    
    target_col = config['target']['column_name']
    X_train = train_df.drop(target_col, axis=1)
    y_train = train_df[target_col]
    X_test = test_df.drop(target_col, axis=1)
    y_test = test_df[target_col]
    
    # Treinar
    trainer.train(X_train, y_train, use_cross_validation=True)
    
    # Avaliar
    metrics = trainer.evaluate(X_test, y_test)
    
    # Salvar
    trainer.save()
    
    # Exibir top features
    print('\n' + '='*80)
    print('TOP 20 FEATURES MAIS IMPORTANTES')
    print('='*80)
    print(trainer.get_feature_importance(top_n=20).to_string(index=False))
    
    print('\n' + '='*80)
    print('‚úÖ TREINAMENTO DE LIGHTGBM CONCLU√çDO COM SUCESSO!')
    print('='*80)
    print(f'\nüìä M√©tricas Finais:')
    print(f'   Acur√°cia: {metrics["accuracy"]:.4f}')
    print(f'   Precis√£o: {metrics["precision"]:.4f}')
    print(f'   Recall: {metrics["recall"]:.4f}')
    print(f'   F1-Score: {metrics["f1_score"]:.4f}')
    print(f'   ROC-AUC: {metrics["auc"]:.4f}')
    print(f'\nüìÅ Resultados salvos em: {trainer.output_dir}')
    print('='*80)


if __name__ == '__main__':
    main()
